import json

# ====== 1. é…ç½® ======
# è¾“å…¥çš„JSONæ–‡ä»¶å (ç”±ä¹‹å‰çš„è„šæœ¬ç”Ÿæˆ)
INPUT_JSON_FILE = "class_hierarchy_complete.json"

# è¾“å‡ºçš„JSONæ–‡ä»¶å
OUTPUT_SENTENCES_JSON_FILE = "generated_sentences_by_class.json"

# æ˜¯å¦åœ¨å¥å­çš„ä¸­é—´éƒ¨åˆ†ä½¿ç”¨è¿‘ä¼¼è¯ (synonyms)ã€‚
USE_SYNONYMS = True
# ========================

def load_data(filename):
    """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®å¹¶å¤„ç†é”™è¯¯ã€‚"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®æ–‡ä»¶: {filename}")
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ° -> {filename}")
        return None
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ {filename} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚")
        return None

def get_article(word):
    """æ ¹æ®å•è¯é¦–å­—æ¯è¿”å›æ­£ç¡®çš„å† è¯ 'a' æˆ– 'an'ã€‚"""
    if not word:
        return "a"
    return "an" if word[0] in "aeiou" else "a"

def generate_sentences_by_class(data):
    """
    æ ¹æ®åŠ è½½çš„æ•°æ®ï¼Œç”Ÿæˆä¸€ä¸ªä»¥ä¸»ç±»åˆ«ä¸ºé”®ï¼Œå¥å­åˆ—è¡¨ä¸ºå€¼çš„å­—å…¸ã€‚
    """
    if not data:
        return {}

    # æœ€ç»ˆçš„æ•°æ®ç»“æ„å°†æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè€Œä¸æ˜¯åˆ—è¡¨
    sentences_by_class = {}
    total_sentence_count = 0
    print("\n--- å¼€å§‹ç”Ÿæˆå¥å­ ---")

    # éå†JSONä¸­çš„æ¯ä¸€ä¸ªä¸»ç±»åˆ« (e.g., "car", "truck")
    for main_class, attributes in data.items():
        # ä¸ºå½“å‰ä¸»ç±»åˆ«åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜æ”¾å¥å­
        sentences_by_class[main_class] = []
        
        main_class_lower = main_class.lower()
        
        # æ•°æ®éªŒè¯å’Œå‡†å¤‡
        sub_categories = attributes.get("sub-categories", [])
        super_categories = attributes.get("super-categories", [])
        synonyms = attributes.get("synonyms", [])

        if not sub_categories or not super_categories:
            print(f"ğŸŸ¡ è­¦å‘Š: ç±»åˆ« '{main_class}' ç¼ºå°‘å­ç±»æˆ–çˆ¶ç±»ï¼Œå·²è·³è¿‡ã€‚")
            continue

        # å‡†å¤‡å¥å­çš„ä¸­é—´éƒ¨åˆ†
        middle_terms = {main_class_lower}
        if USE_SYNONYMS and synonyms:
            middle_terms.update([s.lower() for s in synonyms])
        
        # ç”Ÿæˆæ‰€æœ‰å¥å­ç»„åˆ
        for sub_cat in sub_categories:
            sub_cat_lower = sub_cat.lower()
            article1 = get_article(sub_cat_lower)

            for middle in middle_terms:
                for super_cat in super_categories:
                    super_cat_lower = super_cat.lower()
                    
                    sentence = (
                        f"{article1} {sub_cat_lower}, "
                        f"which is a {middle}, "
                        f"which is a {super_cat_lower}"
                    )
                    # å°†ç”Ÿæˆçš„å¥å­æ·»åŠ åˆ°å¯¹åº”ä¸»ç±»åˆ«çš„åˆ—è¡¨ä¸­
                    sentences_by_class[main_class].append(sentence)
        
        class_sentence_count = len(sentences_by_class[main_class])
        total_sentence_count += class_sentence_count
        print(f"  å·²ä¸º '{main_class}' ç”Ÿæˆ {class_sentence_count} æ¡å¥å­ã€‚")

    print(f"\næ€»è®¡ç”Ÿæˆ {total_sentence_count} æ¡å¥å­ã€‚")
    return sentences_by_class

def save_to_json(data_dict, filename):
    """å°†å­—å…¸æ•°æ®ä»¥ç¾åŒ–çš„æ ¼å¼ä¿å­˜åˆ°JSONæ–‡ä»¶ã€‚"""
    if not data_dict:
        print("ğŸŸ¡ è­¦å‘Š: æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•°æ®ï¼Œæœªåˆ›å»ºæ–‡ä»¶ã€‚")
        return

    try:
        with open(filename, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨ json.dump æ¥å†™å…¥æ•°æ®
            # indent=4: ç¾åŒ–è¾“å‡ºï¼Œè‡ªåŠ¨ç¼©è¿›4ä¸ªç©ºæ ¼
            # ensure_ascii=False: ç¡®ä¿ä¸­æ–‡å­—ç¬¦æˆ–å…¶ä»–éASCIIå­—ç¬¦èƒ½è¢«æ­£ç¡®å†™å…¥
            json.dump(data_dict, f, indent=4, ensure_ascii=False)
        print(f"\nâœ… æˆåŠŸ! æ•°æ®å·²æŒ‰ç±»åˆ«ä¿å­˜åˆ°JSONæ–‡ä»¶: {filename}")
    except IOError as e:
        print(f"âŒ é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ {filename}ã€‚é”™è¯¯ä¿¡æ¯: {e}")

# ä¸»æ‰§è¡Œå‡½æ•°
if __name__ == "__main__":
    # æ­¥éª¤ 1: åŠ è½½æ•°æ®
    class_data = load_data(INPUT_JSON_FILE)

    if class_data:
        # æ­¥éª¤ 2: ç”ŸæˆæŒ‰ç±»åˆ«ç»„ç»‡çš„å¥å­å­—å…¸
        sentences_data = generate_sentences_by_class(class_data)
        
        # æ­¥éª¤ 3: å°†å­—å…¸ä¿å­˜ä¸ºJSONæ–‡ä»¶
        save_to_json(sentences_data, OUTPUT_SENTENCES_JSON_FILE)